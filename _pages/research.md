---
permalink: "/research/"
author_profile: true
---

## Publications

* [SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient](https://arxiv.org/abs/1811.04504). Aaron Mishkin, Frederik Kunstner, Didrik Nielsen, Mark Schmidt, Mohammad Emtiyaz Khan. In *Conference on Neural Information Processing Systems (NIPS)*, 2018.

* [Fast yet Simple Natural-Gradient Descent for Variational Inference in Complex Models](https://arxiv.org/abs/1807.04489). Mohammad Emtiyaz Khan, Didrik Nielsen. In *International Symposium on Information Theory and Its Applications (ISITA)*, 2018.

* [Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam](https://arxiv.org/abs/1806.04854). Mohammad Emtiyaz Khan, Didrik Nielsen, Voot Tangkaratt, Wu Lin, Yarin Gal, Akash Srivastava. In *International Conference on Machine Learning (ICML)*, 2018.

## Preprints

* [Variational Adaptive-Newton Method for Explorative Learning](https://arxiv.org/abs/1711.05560). Mohammad Emtiyaz Khan, Wu Lin, Voot Tangkaratt, Zuozhu Liu, Didrik Nielsen. On *arXiv*, 2017.

## Workshop Papers

* [Variational Adaptive-Newton Method](http://approximateinference.org/2017/accepted/KhanEtAl2017.pdf). Mohammad Emtiyaz Khan, Wu Lin, Voot Tangkaratt, Zuozhu Liu, Didrik Nielsen. In *Workshop on Advances in Approximate Bayesian Inference, NIPS*, 2017.

* [Natural-Gradient Stochastic Variational Inference for Non-Conjugate
Structured Variational Autoencoder](https://deepstruct.github.io/ICML17/1stDeepStructWS_paper_10.pdf). Wu Lin, Mohammad Emtiyaz Khan, Nicolas Hubacher, Didrik Nielsen. In *Workshop on Deep Structured Prediction, ICML*, 2017.


## Thesis

* [Tree Boosting With XGBoost - Why Does XGBoost Win "Every" Machine Learning Competition?](https://ntnuopen.ntnu.no/ntnu-xmlui/bitstream/handle/11250/2433761/16128_FULLTEXT.pdf). Didrik Nielsen. MSc Thesis, 2016.
